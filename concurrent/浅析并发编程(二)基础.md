#### 浅析并发编程(二)基础

1. 并发与并行

  **并发**:指的是一段时间内多个任务同时执行，且都没有执行结束。一段时间是由多个时间点组成，而在单个时间点，仍然只有一个任务正在执行。此外，如果在单个时间片之内，该任务执行结束，并继续执行下一个任务。这样就变成了串行。

  **并行**:指的是同一时刻多个任务同时执行。在单核CPU下，只能并发无法并行。

   我们先一起来看单核CPU下的并发。

<img src="..\resource\pictures\concurrent\single_cpu.png" alt="单核cpu并发" style="zoom:75%;" />

向右箭头代表CPU，该箭头被切割成多个部分，每一个部分代表一个时间片。每一块部分都被着色，蛋黄色和橘黄色分别是两个不同的任务现在两个线程来执行。图示中，`Thread1`和`Thread2`执行完对应的任务都花了三个时间片。由于单核单处理器下，只存在并发不存在并行，我们就接着来看，多核多处理器下的并发与并行。

<img src="..\resource\pictures\concurrent\multicpu_concurrent.png" alt="多cpu并发" style="zoom:75%;" />

 上图中，我们有`CPU1`和`CPU2`可以用来调度，我们也有两个任务分别由`Thread1`和`Thread2`来执行。`Thread1`和`Thread2`在执行各自任务的时候都需要用两个同步代码块，`Thread1`在第一个时间片中，进入该同步代码块执行对应任务，然后遇到wait系列方法让出了CPU，但此时没有新增任务进来被`CPU1`调度。`CPU1`在这这段时间内处于空闲状态。此时`Thread2`刚好处于就绪状态且没有线程正在访问`同步代码块1`,于是开始执行。当执行完之后,`Thread1`又恰好处于就绪状态且被`CPU1`调度并执行，进入`同步代码块2`，继续执行对应任务。此时，`Thread2`获取不到对应的锁，线程被阻塞，且没有新的处于就绪状态的线程供`CPU2`调度，`CPU2`处于闲置状态。当`Thread1`执行完对应的任务之后，`Thread2`获取到对应的锁，重新处于就绪状态，`CPU2`继续调度并执行完该任务。所以，尽管存在多个CPU但是因为`Thread1`和`Thread2`需要共用同步代码块，而该代码块一次只能被一个线程访问，所以造成线程出现阻塞，而无法并行执行。

<img src="..\resource\pictures\concurrent\multicpu_parallel.png" alt="多cpu并行" style="zoom:75%;" />

如上图，`Thread1`和`Thread2`对应的任务之间不存在共享变量，所以两个线程可以并行执行且提高了吞吐量。

2. 多线程并发编程的意义

从硬件上来讲，在单处理器单核的情况下，对于多线程并发来说意义不大。因为每个线程执行完对应的时间片之后，需要进行上下文的切换。但是在多处理器多核的情况下，每个线程可能会分到属于自己的CPU，这样就减少了上下文切换带来的开销。从需求上来讲，对于应用系统的吞吐量有了更高了要求，需要在一段时间内同时处理多个多个请求。所以，无论是从硬件上、或者是对于应用的性能上，多线程并发编程变得更加有意义了。

3. CPU Cache与缓存一致性问题

计算机的组成部分：运算器、控制器、存储器、输入、输出。先不讨论输入输出设备的情况下，运算器和控制器主要由CPU负责，存储器主要由RAM和Disk负责。CPU的运算速度很快，而从内存中读取的速度很慢，因此存在着矛盾，这样CPU Cache就应运而生了。而现如今，CPU Cache通常有`L1`、`L2`、`L3`的出现。

<img src="..\resource\pictures\concurrent\cpu_architecture.png" alt="cpu_architecture" style="zoom:75%;" />

如上图是一个双处理器四核八线程的缓存结构图，`L1`由两部分组成 `L1 I` 表示`L1 Instruction`适用于存储指令，`L1 D`表示`L1 data`适用于存储数据。`Core1`和`Core2`共用`L3`缓存。`L3`和RAM通过总线进行访问。

我们先来看一个简单的例子。

假设RAM中有一个变量a = 0，`Processor1`中有`Core1`和`Core2`。Core 1尝试加载a，`L1`中没有找到，`L2`中也没有找到，`L3`中也没有找到，最后在RAM中找到了。接着`Core1`对a进行了数据操作，使得a= 1，并同步更新`L1`、`L2`、`L3`，最终更新了RAM中的a的值，此时a=1。

`Core2`尝试加载a，`L1`中没有找到，`L2`中也没有找到，最终在`L3`中找到了，此时a=1。`Core2`也对a进行了数据操作，使得a=2。并同步更新了`L1`、`L2`、`L3`最终同步更新了RAM。

此时`Core1`尝试加载a，`Core1`的`L1`存在a直接返回，得到的值仍旧是a=1。此时出现了`Core1`的`L1`、`L2`与`Core2` 的`L1`、`L2` 和共用的`L3`多级缓存之间关于变量a数值的不同，出现了**多级缓存的一致性问题**。

* `MESI`

出现缓存一致性的问题之后，一般的解决方式有对总线加锁，导致其他处理器不能操作其他内存地址的数据。这种方式并不是很理想，所以可以通过缓存一致性协议来处理这个问题，比较常见的就是Intel的`MESI`协议。而CPU Cache与RAM数据交互的最小单位是Cache Line，通常Cache Line的大小为64 byte。我们继续来看`MESI`协议，`MESI`由Modified、Exclusive、Shared、Invalid四种状态组成。

|   状态    |                             描述                             |
| :-------: | :----------------------------------------------------------: |
| Modified  |     表示该Cache Line已经被修改了，但是还没有更新到RAM中      |
| Exclusive |              表示该Cache Line只被当前处理器使用              |
|  Shared   |                表示该Cache Line被多个CPU使用                 |
|  Invalid  | 表示该Cache Line是失效的，如果需要使用，需要重新从RAM进行加载 |

我们通过一个例子来看这四种状态之间的转变。

<img src="..\resource\pictures\concurrent\MultiCPU1.png" alt="MultiCPU1" style="zoom:75%;" />

假设RAM中有一个变量x=0，`CPU1`尝试加载变量x，且当前只有`CPU1`拥有该变量的缓存，此时`CPU1`对应的Cache Line的状态为Exclusive。

`CPU2`也尝试加载变量x，此时`CPU1`和`CPU2`都拥有了关于变量x的缓存，对应的Cache Line的状态都为Shared。

`CPU1`尝试修改变量x，此时`CPU1`对应的Cache Line的状态为Modified，并且`CPU1`向其他拥有了该变量缓存的CPU发送了`invaild`指令，`CPU2`收到该指令之后，发送`ACK`确认响应，并把对应的Cache Line的状态置为Invalid的。`CPU1`在收到`ACK`确认指令之后，将该变量的改动同步到缓存和RAM中。此时`CPU1`关于该变量的Cache Lined的状态为Exclusive。

`CPU2`想要对变量x进行处理，发现对应的Cache Line的状态为Invalid，所以重新从RAM加载该变量。

* Store Buffers

我们把目光放在上述例子中的`CPU1`发送invalid指令，直到`CPU1`收到所有的`ACK`确认消息，可以发现这边的操作是同步的。意味着`CPU1`在这段时间内处于一个空窗期，这不是我们期望的。

<img src="..\resource\pictures\concurrent\store_buffer.png" alt="store_buffer" style="zoom:75%;" />

基于避免CPU在等待`ACK`确认消息期间导致CPU出现闲置的情况，CPU修改完变量之后，将其对应的Cache Line的状态由Shared变成Modified，然后发送invalid指令，之后将修改的变量推送到Store Buffer中，继续执行后面的指令，等到收到关于该变量的`ACK`确认消息之后，再将该变量刷入缓存，最后同步到RAM中。如果当前CPU将变更后的变量推送到Store Buffer中，但是在之后的运算中需要使用到该变量的值，但是此时变更的变量还没有收到`ACK`确认消息，导致缓存中的值还是旧数据。此时，就需要该CPU先访问Store Buffer，如果没找到再到缓存中寻找，这样的情况称之为Store Forwarding。但即便如此，当`CPU1`将变更的变量推送到Store Buffer中，但是没有推送到Cache和RAM中，对于其他的CPU来说，当前变量的缓存仍然是旧值。即便重新从RAM中加载该变量，由于该变量的最新值没有推送进来，所以该变量加载完还是旧值。此时需要**内存屏障**来解决这个问题，在关于该变量的数据操作之前，需要将Store Buffer中的关于该变量之前的变更，推送到缓存中，进而推送到RAM中。

* Invalidate Queue

但是，即便引入了Store Buffers。`CPU0`将未收到`ACK`确认消息的推送到Store Buffer中，而如果其他拥有该变量的`CPU1`正在执行别的指令，导致`ACK`确认消息出现延时，Store Buffer中的数据没有及时推送到缓存中，导致Store Buffer中空间不够，再次导致`CPU0`的操作变成同步。

基于`ACK`消息出现延时，导致Store Buffer空间不足，最终导致CPU变成同步处理。引入了Invalidate Queue，当CPU接收到invalid指令之后，会将该消息存放在Invalidate Queue中，之后直接返回`ACK`确认消息。最后，对应的Cache Line状态变成Invalid。

<img src="..\resource\pictures\concurrent\invalidate_queue.png" alt="invalidate_queue" style="zoom:75%;" />

但是如果该消息存放在Invalidate Queue中，并直接返回`ACK`确认消息。当前CPU需要对该变量进行数据操作，但是此时CPU并不知道对应的Cache Line的状态其实应该是Invalid，需要到从RAM中重新加载该变量。那么由于这样的延时，就是再次出现问题。那么此时就需要**内存屏障**来解决这个问题，也就是需要等到Invalidate Queue中item最终应用到缓存中 ，也就是说需要等到缓存中对应的Cache Line的状态变成Invalid之后，才执行之后的操作。而JAVA对于内存屏障的指令进行了统一封装，对应的模型就是JAVA内存模型，也就是`JMM`。

4. `JMM`

`JMM`指定了不同线程之间如何以及何时可以看到其他线程写入的共享变量的值，以及如何确保同步访问这些共享变量。`JMM`规定了每一个运行在`JVM`中的线程拥有自己的工作空间，通常关于基本类型的变量存放在该工作空间，但是如果该基本类型是成员变量的情况下，将会存放在主内存中。此外，关于基本类型对应的对象以及其他引用类型都存放在主内存中。

<img src="..\resource\pictures\concurrent\JMM.png" alt="JMM" style="zoom:75%;" />

但是`JMM`和`JVM`的区别又在什么地方呢？事实上，`JMM`只是一个抽象的模型，它只是规定了线程如何通过内存进行交互。而`JVM`是具体存在的，是关于`JMM`的一个具体实现。就像`MVC`只是一种思想，而与之对应的`SpringMVC`则是具体的实现。

本篇中`MESI`虽然可以解决缓存一致性的问题，但是却不能保证对于变量的修改对于其他线程来说即时可见。下一篇我们可以看到`JMM`是如何解决这种即时可见性的问题，事实上`JMM`还可以解决原子性问题、有序性问题。











